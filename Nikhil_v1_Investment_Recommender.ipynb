{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pPLiGuln9SHw2azMuUffnSWve7R9iC8T","timestamp":1736589812183},{"file_id":"1iU-jb8AOY6hrQQKP3x6nmq1LUrmIrXn-","timestamp":1736584990849}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a0c440444dd54c05bc8f108a24be51c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e555ce4e2452472e8eb29ba5b3093b5f","IPY_MODEL_9df4652a857c46d0a41f5fd86e3b9675","IPY_MODEL_a97cd7e98e80441e801ae2f1d21c2ebe"],"layout":"IPY_MODEL_34aa05e758774eb28c64ff9a77e081d9"}},"e555ce4e2452472e8eb29ba5b3093b5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_088a6a37c4074a2388205475dde5b3e9","placeholder":"​","style":"IPY_MODEL_853ebb896f184cc4957098ecd4a164ec","value":"Loading checkpoint shards: 100%"}},"9df4652a857c46d0a41f5fd86e3b9675":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e117d96aee444249a4bd7e58921981e5","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e6dd690293644779fcd41954ffeae4c","value":2}},"a97cd7e98e80441e801ae2f1d21c2ebe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fe5a3732ef54d558c951aaff804590e","placeholder":"​","style":"IPY_MODEL_e93bae96facb43dfb0a09f59d988910d","value":" 2/2 [00:57&lt;00:00, 26.31s/it]"}},"34aa05e758774eb28c64ff9a77e081d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"088a6a37c4074a2388205475dde5b3e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"853ebb896f184cc4957098ecd4a164ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e117d96aee444249a4bd7e58921981e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e6dd690293644779fcd41954ffeae4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fe5a3732ef54d558c951aaff804590e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e93bae96facb43dfb0a09f59d988910d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f69eba80913409d9f6dfc2bd0b3715a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45d46558ccde443cada1c8ed5ef6c1fb","IPY_MODEL_d968dc73ee1a41ddb331e792de437fe4","IPY_MODEL_b04256d204cf4eebbcfab04238427bac"],"layout":"IPY_MODEL_406e856e67254867824c1fae2682a009"}},"45d46558ccde443cada1c8ed5ef6c1fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07586706bf0b49088052299f2d19effa","placeholder":"​","style":"IPY_MODEL_63e30aa7b7c24473bb8cf4e5689400ec","value":"Map: 100%"}},"d968dc73ee1a41ddb331e792de437fe4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c93e258b4ea942de91c0fe6f31e9916e","max":288,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60957a3fb2a94c8c97b80ad991da1c3d","value":288}},"b04256d204cf4eebbcfab04238427bac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52e4be24c7ce4bdca54073efdc438ced","placeholder":"​","style":"IPY_MODEL_777ec2a084864b1bba2d66e51b8c4a30","value":" 288/288 [00:00&lt;00:00, 1976.95 examples/s]"}},"406e856e67254867824c1fae2682a009":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07586706bf0b49088052299f2d19effa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63e30aa7b7c24473bb8cf4e5689400ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c93e258b4ea942de91c0fe6f31e9916e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60957a3fb2a94c8c97b80ad991da1c3d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52e4be24c7ce4bdca54073efdc438ced":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"777ec2a084864b1bba2d66e51b8c4a30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1d1d2214269417f8f552ff331e3c2d1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c5c619d280646e18bd938c5f655e949","IPY_MODEL_18b2da20fee847a59c8df89d6c7c3dbf","IPY_MODEL_752b36acc5724438bfa821dfa1db2518"],"layout":"IPY_MODEL_4453335771524a8ba9503445423b16e4"}},"9c5c619d280646e18bd938c5f655e949":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f84af7c135474ded8fec280bc9959fb1","placeholder":"​","style":"IPY_MODEL_b94bbfe741304160a44d72f040e82201","value":"config.json: 100%"}},"18b2da20fee847a59c8df89d6c7c3dbf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbfbf859c02a466c89723c8f82f6e8cb","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92c09ecc585b4911bc1e8ade267e06bb","value":612}},"752b36acc5724438bfa821dfa1db2518":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cb22b1c24874ce29bf051796da1aea1","placeholder":"​","style":"IPY_MODEL_101923033bcd416bba840be779df9697","value":" 612/612 [00:00&lt;00:00, 10.2kB/s]"}},"4453335771524a8ba9503445423b16e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f84af7c135474ded8fec280bc9959fb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b94bbfe741304160a44d72f040e82201":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbfbf859c02a466c89723c8f82f6e8cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92c09ecc585b4911bc1e8ade267e06bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3cb22b1c24874ce29bf051796da1aea1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"101923033bcd416bba840be779df9697":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75a25e80847c4d389509642655b29b77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c678d6f9d9642ea9d1461704ca6d884","IPY_MODEL_aad37e9ce16b49d198d1f1726f1970f1","IPY_MODEL_a1beabf33b2e472cb918273ab8c4f29a"],"layout":"IPY_MODEL_efd1288716e3406587dceab53a8be604"}},"2c678d6f9d9642ea9d1461704ca6d884":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_439e8f7df38e4c21910f49c5a97a5ed1","placeholder":"​","style":"IPY_MODEL_f69bb25d848f4301912da43767acfedb","value":"model.safetensors: 100%"}},"aad37e9ce16b49d198d1f1726f1970f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_213e758a895b44c081307211c09a89f1","max":90868376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b2ede2dacae4fb6bb8288bc19aeb0c3","value":90868376}},"a1beabf33b2e472cb918273ab8c4f29a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_044676487ff44eb2a26283a1d1cf5507","placeholder":"​","style":"IPY_MODEL_96f3054a34874a4f92052ba858513de3","value":" 90.9M/90.9M [00:04&lt;00:00, 37.7MB/s]"}},"efd1288716e3406587dceab53a8be604":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"439e8f7df38e4c21910f49c5a97a5ed1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f69bb25d848f4301912da43767acfedb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"213e758a895b44c081307211c09a89f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b2ede2dacae4fb6bb8288bc19aeb0c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"044676487ff44eb2a26283a1d1cf5507":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96f3054a34874a4f92052ba858513de3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38177054c4724036b378964c4a115c56":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75aa067577044ac0929c3fbe9eaecb32","IPY_MODEL_5363636a20b34bef8adec9c158f66cba","IPY_MODEL_7f5fbc36034047f28636a3f553ba31ed"],"layout":"IPY_MODEL_b2b1e7a8b26942f8bbca519b1e6f8cff"}},"75aa067577044ac0929c3fbe9eaecb32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87afc91a30bb4cb7885660f8f218db23","placeholder":"​","style":"IPY_MODEL_87c3ec6b40274528b5ac6f09ea313386","value":"tokenizer_config.json: 100%"}},"5363636a20b34bef8adec9c158f66cba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a21454e851e4577a09e381a0a965efc","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61ac09c8ad654912b640ccfb36a636ed","value":350}},"7f5fbc36034047f28636a3f553ba31ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75fe3725a2dc45098029aaff5dd0bb72","placeholder":"​","style":"IPY_MODEL_41cc20a7055b45839df5900ad2aeb677","value":" 350/350 [00:00&lt;00:00, 6.92kB/s]"}},"b2b1e7a8b26942f8bbca519b1e6f8cff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87afc91a30bb4cb7885660f8f218db23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87c3ec6b40274528b5ac6f09ea313386":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a21454e851e4577a09e381a0a965efc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61ac09c8ad654912b640ccfb36a636ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75fe3725a2dc45098029aaff5dd0bb72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41cc20a7055b45839df5900ad2aeb677":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d42b23cf5835420ea1817605f08b51dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d59c2b4cb2e44d893ed902b96bc0fbc","IPY_MODEL_a35d7c87f5814ec0b2271d735a91498a","IPY_MODEL_d8444feee8d54f608ea3b156e6e8496f"],"layout":"IPY_MODEL_6f6089fc7964445ca7728f81013406f1"}},"3d59c2b4cb2e44d893ed902b96bc0fbc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_074b8227e8c34efc8d057a1a87b0a235","placeholder":"​","style":"IPY_MODEL_142e7cefb168423387cb311b3d1730ca","value":"vocab.txt: 100%"}},"a35d7c87f5814ec0b2271d735a91498a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a5a301202b24274a2fdf08f6bb6c3e4","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc4aab3fa54b4558bf344c6155f73033","value":231508}},"d8444feee8d54f608ea3b156e6e8496f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0870ecdc3454ee19e1b49b449f2e34f","placeholder":"​","style":"IPY_MODEL_1721e4aaa3c84eb4ba0366d7f6107b65","value":" 232k/232k [00:00&lt;00:00, 2.87MB/s]"}},"6f6089fc7964445ca7728f81013406f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"074b8227e8c34efc8d057a1a87b0a235":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"142e7cefb168423387cb311b3d1730ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a5a301202b24274a2fdf08f6bb6c3e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc4aab3fa54b4558bf344c6155f73033":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0870ecdc3454ee19e1b49b449f2e34f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1721e4aaa3c84eb4ba0366d7f6107b65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"015b3d49e00c4aea8758ba22921a3872":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b050aed961044b7bc5601cd3e8582f7","IPY_MODEL_67092193bb4d46de95495230b2274574","IPY_MODEL_0ae687fee4e2476ab1a1b4dc7dd212b1"],"layout":"IPY_MODEL_2095a66dc0aa439e9ddde8c4c4ec2967"}},"6b050aed961044b7bc5601cd3e8582f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be80fffeba734553a786a3928ab737bd","placeholder":"​","style":"IPY_MODEL_b6380662e5934df087283d5e9621b475","value":"tokenizer.json: 100%"}},"67092193bb4d46de95495230b2274574":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c356e5d61304afb9650c3150d448103","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cacd9387fb9f4fd6af55d1b9883793e3","value":466247}},"0ae687fee4e2476ab1a1b4dc7dd212b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a13540f4ebf4cbabd08c21b719289af","placeholder":"​","style":"IPY_MODEL_4a38da4775924d7bab5b50934cd99dac","value":" 466k/466k [00:00&lt;00:00, 3.58MB/s]"}},"2095a66dc0aa439e9ddde8c4c4ec2967":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be80fffeba734553a786a3928ab737bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6380662e5934df087283d5e9621b475":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c356e5d61304afb9650c3150d448103":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cacd9387fb9f4fd6af55d1b9883793e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a13540f4ebf4cbabd08c21b719289af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a38da4775924d7bab5b50934cd99dac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97e699da53f24284872ee144d6a7c559":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45f5a728791b4c6eaccc086df8577afa","IPY_MODEL_da559cb2d86c40c0af25983b2aad2824","IPY_MODEL_323200ae36c449cfa2e56f5de49ede8c"],"layout":"IPY_MODEL_797538783986442986b108876206e641"}},"45f5a728791b4c6eaccc086df8577afa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d45a47989fb343b0b68d613bed765376","placeholder":"​","style":"IPY_MODEL_4aa5e08c240f4ffbaa93f8e958b37332","value":"special_tokens_map.json: 100%"}},"da559cb2d86c40c0af25983b2aad2824":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_365a7bc031774bc4a359073d0e4acbe4","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d93b5ba1bad64fc5b4e82a77c410d54b","value":112}},"323200ae36c449cfa2e56f5de49ede8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f30dd1abd0c4a3687f45f29cce98028","placeholder":"​","style":"IPY_MODEL_5f7cf3df17e04d34875ecd88acbae3b5","value":" 112/112 [00:00&lt;00:00, 2.82kB/s]"}},"797538783986442986b108876206e641":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d45a47989fb343b0b68d613bed765376":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aa5e08c240f4ffbaa93f8e958b37332":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"365a7bc031774bc4a359073d0e4acbe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d93b5ba1bad64fc5b4e82a77c410d54b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f30dd1abd0c4a3687f45f29cce98028":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f7cf3df17e04d34875ecd88acbae3b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install yfinance\n","!pip install transformers\n","!pip install datasets\n","!pip install accelerate\n","!pip install faiss-cpu\n","!pip install py2neo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJ7YDxq-A72p","executionInfo":{"status":"ok","timestamp":1727904310361,"user_tz":-330,"elapsed":20217,"user":{"displayName":"Udit Kosuru","userId":"07698625486027486284"}},"outputId":"457a920a-cd1b-4aae-cf9a-48fb194241a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.43)\n","Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.2.2)\n","Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\n","Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n","Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n","Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n","Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n","Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.4)\n","Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.6)\n","Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n","Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.8.30)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n","Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n","Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.8.0.post1\n","Collecting py2neo\n","  Downloading py2neo-2021.2.4-py2.py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from py2neo) (2024.8.30)\n","Collecting interchange~=2021.0.4 (from py2neo)\n","  Downloading interchange-2021.0.4-py2.py3-none-any.whl.metadata (1.9 kB)\n","Collecting monotonic (from py2neo)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from py2neo) (24.1)\n","Collecting pansi>=2020.7.3 (from py2neo)\n","  Downloading pansi-2020.7.3-py2.py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: pygments>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from py2neo) (2.18.0)\n","Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from py2neo) (1.16.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from py2neo) (2.2.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from interchange~=2021.0.4->py2neo) (2024.2)\n","Downloading py2neo-2021.2.4-py2.py3-none-any.whl (177 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interchange-2021.0.4-py2.py3-none-any.whl (28 kB)\n","Downloading pansi-2020.7.3-py2.py3-none-any.whl (10 kB)\n","Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Installing collected packages: monotonic, pansi, interchange, py2neo\n","Successfully installed interchange-2021.0.4 monotonic-1.6 pansi-2020.7.3 py2neo-2021.2.4\n"]}]},{"cell_type":"code","source":["import yfinance as yf\n","import random\n","import json\n","\n","# Company Codes\n","company_tickers = [\n","    \"AAPL\", \"TSLA\", \"GOOGL\", \"AMZN\", \"MSFT\", \"FB\", \"NFLX\", \"NVDA\", \"INTC\", \"AMD\",\n","    \"BABA\", \"BA\", \"WMT\", \"PFE\", \"MRNA\", \"JPM\", \"GS\", \"V\", \"MA\", \"PYPL\",\n","    \"KO\", \"PEP\", \"XOM\", \"CVX\", \"SPCE\", \"UBER\", \"LYFT\", \"TWTR\", \"SHOP\", \"SQ\",\n","    \"T\", \"VZ\", \"IBM\", \"ORCL\", \"CSCO\", \"ADBE\", \"CRM\", \"ZM\", \"DOCU\", \"SNOW\",\n","    \"DIS\", \"SBUX\", \"MCD\", \"NKE\", \"HD\", \"COST\", \"LOW\", \"TGT\", \"WBA\", \"CVS\",\n","    \"TXN\", \"QCOM\", \"MU\", \"AVGO\", \"LRCX\", \"AMD\", \"REGN\", \"GILD\", \"BIIB\", \"MRK\",\n","    \"LLY\", \"ABBV\", \"ABT\", \"BMY\", \"DHR\", \"MDT\", \"ISRG\", \"SYK\", \"BDX\", \"ZTS\",\n","    \"NVS\", \"AZN\", \"SNY\", \"ROG\", \"BIDU\", \"JD\", \"PDD\", \"NTES\", \"TME\", \"BILI\",\n","    \"TSM\", \"SNE\", \"NTDOY\", \"NSRGY\", \"HSBC\", \"RY\", \"TD\", \"BCS\", \"BNS\", \"BBVA\",\n","    \"DB\", \"CS\", \"UBS\", \"JPM\", \"BAC\", \"C\", \"MS\", \"WFC\", \"GS\", \"AXP\"\n","]\n","\n","# Extract financial data\n","def fetch_and_save_financial_data(ticker_list, num_companies=100):\n","    financial_data = []\n","    selected_tickers = random.sample(ticker_list, num_companies)\n","\n","    for ticker in selected_tickers:\n","        print(f\"Fetching financial data for {ticker}...\")\n","        stock = yf.Ticker(ticker)\n","        balance_sheet = stock.balance_sheet\n","\n","        if not balance_sheet.empty:\n","            #  Extract financial data, defaulting to None if missing\n","            try:\n","                total_assets = balance_sheet.loc[\"Total Assets\"].iloc[0]\n","            except KeyError:\n","                total_assets = None\n","                print(f\"Total Assets not found for {ticker}\")\n","\n","            # Checking alternative fields if primary ones are missing\n","            try:\n","                total_liabilities = balance_sheet.loc[\"Total Liabilities\"].iloc[0]\n","            except KeyError:\n","                total_liabilities = balance_sheet.loc[\"Long Term Debt\"].iloc[0] if \"Long Term Debt\" in balance_sheet.index else None\n","                if total_liabilities is None:\n","                    print(f\"Total Liabilities not found for {ticker} (tried alternative fields).\")\n","\n","            try:\n","                total_equity = balance_sheet.loc[\"Total Stockholder Equity\"].iloc[0]\n","            except KeyError:\n","                total_equity = balance_sheet.loc[\"Net Worth\"].iloc[0] if \"Net Worth\" in balance_sheet.index else None\n","                if total_equity is None:\n","                    print(f\"Total Stockholder Equity not found for {ticker} (tried alternative fields).\")\n","\n","            # Converting Timestamp to string for JSON serialization\n","            try:\n","                year = str(balance_sheet.columns[0])  # Convert timestamp to string\n","            except Exception:\n","                year = \"Unknown\"\n","\n","            # Appending if at least one piece of financial data is present\n","            if total_assets is not None or total_liabilities is not None or total_equity is not None:\n","                data = {\n","                    \"ticker\": ticker,\n","                    \"Total Assets\": total_assets,\n","                    \"Total Liabilities\": total_liabilities,\n","                    \"Total Stockholder Equity\": total_equity,\n","                    \"Year\": year  # Year as string to avoid JSON serialization issues\n","                }\n","                financial_data.append(data)\n","        else:\n","            print(f\"No balance sheet data found for {ticker}\")\n","\n","    # Saving the fetched data to a file\n","    with open(\"financial_data_100_companies.json\", \"w\") as f:\n","        json.dump(financial_data, f)\n","\n","    print(\"Financial data for 100 companies saved successfully.\")\n","    return financial_data\n","\n","# Fetch and save financial data\n","financial_data = fetch_and_save_financial_data(company_tickers, num_companies=100)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rxYvQSLjBIVg","executionInfo":{"status":"ok","timestamp":1727903710872,"user_tz":-330,"elapsed":25532,"user":{"displayName":"Udit Kosuru","userId":"07698625486027486284"}},"outputId":"b813cc8a-23a8-41b5-b0e1-e7132b7aeb52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fetching financial data for WFC...\n","Total Stockholder Equity not found for WFC (tried alternative fields).\n","Fetching financial data for FB...\n","No balance sheet data found for FB\n","Fetching financial data for MA...\n","Total Stockholder Equity not found for MA (tried alternative fields).\n","Fetching financial data for TSM...\n","Total Stockholder Equity not found for TSM (tried alternative fields).\n","Fetching financial data for SYK...\n","Total Stockholder Equity not found for SYK (tried alternative fields).\n","Fetching financial data for NTDOY...\n","Total Liabilities not found for NTDOY (tried alternative fields).\n","Total Stockholder Equity not found for NTDOY (tried alternative fields).\n","Fetching financial data for BCS...\n","Total Liabilities not found for BCS (tried alternative fields).\n","Total Stockholder Equity not found for BCS (tried alternative fields).\n","Fetching financial data for GOOGL...\n","Total Stockholder Equity not found for GOOGL (tried alternative fields).\n","Fetching financial data for BABA...\n","Total Stockholder Equity not found for BABA (tried alternative fields).\n","Fetching financial data for AMD...\n","Total Stockholder Equity not found for AMD (tried alternative fields).\n","Fetching financial data for LOW...\n","Total Stockholder Equity not found for LOW (tried alternative fields).\n","Fetching financial data for SHOP...\n","Total Stockholder Equity not found for SHOP (tried alternative fields).\n","Fetching financial data for DIS...\n","Total Stockholder Equity not found for DIS (tried alternative fields).\n","Fetching financial data for WMT...\n","Total Stockholder Equity not found for WMT (tried alternative fields).\n","Fetching financial data for LRCX...\n","Total Stockholder Equity not found for LRCX (tried alternative fields).\n","Fetching financial data for TWTR...\n","No balance sheet data found for TWTR\n","Fetching financial data for RY...\n","Total Stockholder Equity not found for RY (tried alternative fields).\n","Fetching financial data for MCD...\n","Total Stockholder Equity not found for MCD (tried alternative fields).\n","Fetching financial data for DOCU...\n","Total Stockholder Equity not found for DOCU (tried alternative fields).\n","Fetching financial data for GILD...\n","Total Stockholder Equity not found for GILD (tried alternative fields).\n","Fetching financial data for GS...\n","Total Stockholder Equity not found for GS (tried alternative fields).\n","Fetching financial data for TME...\n","Total Stockholder Equity not found for TME (tried alternative fields).\n","Fetching financial data for PYPL...\n","Total Stockholder Equity not found for PYPL (tried alternative fields).\n","Fetching financial data for AXP...\n","Total Stockholder Equity not found for AXP (tried alternative fields).\n","Fetching financial data for MSFT...\n","Total Stockholder Equity not found for MSFT (tried alternative fields).\n","Fetching financial data for ROG...\n","Total Stockholder Equity not found for ROG (tried alternative fields).\n","Fetching financial data for ABBV...\n","Total Stockholder Equity not found for ABBV (tried alternative fields).\n","Fetching financial data for ABT...\n","Total Stockholder Equity not found for ABT (tried alternative fields).\n","Fetching financial data for JPM...\n","Total Stockholder Equity not found for JPM (tried alternative fields).\n","Fetching financial data for HSBC...\n","Total Liabilities not found for HSBC (tried alternative fields).\n","Total Stockholder Equity not found for HSBC (tried alternative fields).\n","Fetching financial data for MDT...\n","Total Stockholder Equity not found for MDT (tried alternative fields).\n","Fetching financial data for DB...\n","Total Stockholder Equity not found for DB (tried alternative fields).\n","Fetching financial data for WBA...\n","Total Stockholder Equity not found for WBA (tried alternative fields).\n","Fetching financial data for AAPL...\n","Total Stockholder Equity not found for AAPL (tried alternative fields).\n","Fetching financial data for PFE...\n","Total Stockholder Equity not found for PFE (tried alternative fields).\n","Fetching financial data for BAC...\n","Total Stockholder Equity not found for BAC (tried alternative fields).\n","Fetching financial data for GS...\n","Total Stockholder Equity not found for GS (tried alternative fields).\n","Fetching financial data for T...\n","Total Stockholder Equity not found for T (tried alternative fields).\n","Fetching financial data for TD...\n","Total Stockholder Equity not found for TD (tried alternative fields).\n","Fetching financial data for SNE...\n","No balance sheet data found for SNE\n","Fetching financial data for NSRGY...\n","Total Stockholder Equity not found for NSRGY (tried alternative fields).\n","Fetching financial data for TXN...\n","Total Stockholder Equity not found for TXN (tried alternative fields).\n","Fetching financial data for ZM...\n","Total Liabilities not found for ZM (tried alternative fields).\n","Total Stockholder Equity not found for ZM (tried alternative fields).\n","Fetching financial data for SBUX...\n","Total Stockholder Equity not found for SBUX (tried alternative fields).\n","Fetching financial data for MU...\n","Total Stockholder Equity not found for MU (tried alternative fields).\n","Fetching financial data for INTC...\n","Total Stockholder Equity not found for INTC (tried alternative fields).\n","Fetching financial data for TSLA...\n","Total Stockholder Equity not found for TSLA (tried alternative fields).\n","Fetching financial data for BDX...\n","Total Stockholder Equity not found for BDX (tried alternative fields).\n","Fetching financial data for ZTS...\n","Total Stockholder Equity not found for ZTS (tried alternative fields).\n","Fetching financial data for BA...\n","Total Stockholder Equity not found for BA (tried alternative fields).\n","Fetching financial data for PEP...\n","Total Stockholder Equity not found for PEP (tried alternative fields).\n","Fetching financial data for AVGO...\n","Total Stockholder Equity not found for AVGO (tried alternative fields).\n","Fetching financial data for MRK...\n","Total Stockholder Equity not found for MRK (tried alternative fields).\n","Fetching financial data for SQ...\n","Total Stockholder Equity not found for SQ (tried alternative fields).\n","Fetching financial data for AMD...\n","Total Stockholder Equity not found for AMD (tried alternative fields).\n","Fetching financial data for NVDA...\n","Total Stockholder Equity not found for NVDA (tried alternative fields).\n","Fetching financial data for NTES...\n","Total Stockholder Equity not found for NTES (tried alternative fields).\n","Fetching financial data for DHR...\n","Total Stockholder Equity not found for DHR (tried alternative fields).\n","Fetching financial data for NFLX...\n","Total Stockholder Equity not found for NFLX (tried alternative fields).\n","Fetching financial data for VZ...\n","Total Stockholder Equity not found for VZ (tried alternative fields).\n","Fetching financial data for LYFT...\n","Total Stockholder Equity not found for LYFT (tried alternative fields).\n","Fetching financial data for MRNA...\n","Total Liabilities not found for MRNA (tried alternative fields).\n","Total Stockholder Equity not found for MRNA (tried alternative fields).\n","Fetching financial data for KO...\n","Total Stockholder Equity not found for KO (tried alternative fields).\n","Fetching financial data for REGN...\n","Total Stockholder Equity not found for REGN (tried alternative fields).\n","Fetching financial data for BMY...\n","Total Stockholder Equity not found for BMY (tried alternative fields).\n","Fetching financial data for SNY...\n","Total Stockholder Equity not found for SNY (tried alternative fields).\n","Fetching financial data for JD...\n","Total Stockholder Equity not found for JD (tried alternative fields).\n","Fetching financial data for SNOW...\n","Total Liabilities not found for SNOW (tried alternative fields).\n","Total Stockholder Equity not found for SNOW (tried alternative fields).\n","Fetching financial data for ISRG...\n","Total Liabilities not found for ISRG (tried alternative fields).\n","Total Stockholder Equity not found for ISRG (tried alternative fields).\n","Fetching financial data for ADBE...\n","Total Stockholder Equity not found for ADBE (tried alternative fields).\n","Fetching financial data for BILI...\n","Total Stockholder Equity not found for BILI (tried alternative fields).\n","Fetching financial data for BBVA...\n","Total Stockholder Equity not found for BBVA (tried alternative fields).\n","Fetching financial data for BIDU...\n","Total Stockholder Equity not found for BIDU (tried alternative fields).\n","Fetching financial data for AMZN...\n","Total Stockholder Equity not found for AMZN (tried alternative fields).\n","Fetching financial data for TGT...\n","Total Stockholder Equity not found for TGT (tried alternative fields).\n","Fetching financial data for CS...\n","No balance sheet data found for CS\n","Fetching financial data for MS...\n","Total Stockholder Equity not found for MS (tried alternative fields).\n","Fetching financial data for NKE...\n","Total Stockholder Equity not found for NKE (tried alternative fields).\n","Fetching financial data for PDD...\n","Total Stockholder Equity not found for PDD (tried alternative fields).\n","Fetching financial data for HD...\n","Total Stockholder Equity not found for HD (tried alternative fields).\n","Fetching financial data for BIIB...\n","Total Stockholder Equity not found for BIIB (tried alternative fields).\n","Fetching financial data for NVS...\n","Total Stockholder Equity not found for NVS (tried alternative fields).\n","Fetching financial data for CSCO...\n","Total Stockholder Equity not found for CSCO (tried alternative fields).\n","Fetching financial data for IBM...\n","Total Stockholder Equity not found for IBM (tried alternative fields).\n","Fetching financial data for AZN...\n","Total Stockholder Equity not found for AZN (tried alternative fields).\n","Fetching financial data for JPM...\n","Total Stockholder Equity not found for JPM (tried alternative fields).\n","Fetching financial data for CRM...\n","Total Stockholder Equity not found for CRM (tried alternative fields).\n","Fetching financial data for LLY...\n","Total Stockholder Equity not found for LLY (tried alternative fields).\n","Fetching financial data for CVX...\n","Total Stockholder Equity not found for CVX (tried alternative fields).\n","Fetching financial data for COST...\n","Total Stockholder Equity not found for COST (tried alternative fields).\n","Fetching financial data for XOM...\n","Total Stockholder Equity not found for XOM (tried alternative fields).\n","Fetching financial data for UBER...\n","Total Stockholder Equity not found for UBER (tried alternative fields).\n","Fetching financial data for CVS...\n","Total Stockholder Equity not found for CVS (tried alternative fields).\n","Fetching financial data for C...\n","Total Stockholder Equity not found for C (tried alternative fields).\n","Fetching financial data for UBS...\n","Total Stockholder Equity not found for UBS (tried alternative fields).\n","Fetching financial data for QCOM...\n","Total Stockholder Equity not found for QCOM (tried alternative fields).\n","Fetching financial data for ORCL...\n","Total Stockholder Equity not found for ORCL (tried alternative fields).\n","Fetching financial data for SPCE...\n","Total Stockholder Equity not found for SPCE (tried alternative fields).\n","Fetching financial data for BNS...\n","Total Stockholder Equity not found for BNS (tried alternative fields).\n","Fetching financial data for V...\n","Total Stockholder Equity not found for V (tried alternative fields).\n","Financial data for 100 companies saved successfully.\n"]}]},{"cell_type":"code","source":["# Creating a question-answer dataset using the financial data\n","def prepare_question_answer_dataset(financial_data):\n","    dataset = []\n","\n","    for company in financial_data:\n","        questions = [\n","            f\"What are the total assets of {company['ticker']} in {company['Year']}?\",\n","            f\"What are the total liabilities of {company['ticker']} in {company['Year']}?\",\n","            f\"What is the total shareholder equity of {company['ticker']} in {company['Year']}?\"\n","        ]\n","\n","        answers = [\n","            f\"The total assets of {company['ticker']} in {company['Year']} were {company['Total Assets']} USD.\",\n","            f\"The total liabilities of {company['ticker']} in {company['Year']} were {company['Total Liabilities']} USD.\",\n","            f\"The total shareholder equity of {company['ticker']} in {company['Year']} was {company['Total Stockholder Equity']} USD.\"\n","        ]\n","\n","        for q, a in zip(questions, answers):\n","            dataset.append({\"question\": q, \"answer\": a})\n","\n","    return dataset\n","\n","# Preparing the dataset\n","financial_finetune_dataset = prepare_question_answer_dataset(financial_data)\n","\n","# Saving the dataset as a JSON file\n","with open(\"financial_finetune_dataset.json\", \"w\") as f:\n","    json.dump(financial_finetune_dataset, f)\n","\n","print(\"Financial dataset prepared and saved.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BjiRvbL3BXjc","executionInfo":{"status":"ok","timestamp":1727903710872,"user_tz":-330,"elapsed":7,"user":{"displayName":"Udit Kosuru","userId":"07698625486027486284"}},"outputId":"1db8ca23-c85a-4714-b4c7-c64b8e269df7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Financial dataset prepared and saved.\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW, DataCollatorForLanguageModeling\n","import torch\n","from datasets import Dataset\n","import json\n","from accelerate import Accelerator\n","\n","# Loading the fine-tuning dataset\n","with open(\"financial_finetune_dataset.json\", \"r\") as f:\n","    financial_data = json.load(f)\n","\n","# Preparing the dataset for Hugging Face's format\n","dataset = Dataset.from_list(financial_data)\n","\n","# Loading tokenizer and model\n","model_name = \"NousResearch/LLaMA-2-7b-hf\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# Initializing model with ZeRO-Offload to CPU\n","model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n","\n","# Tokenizing the dataset\n","def tokenize_data(example):\n","    question = example['question']\n","    answer = example['answer']\n","    return tokenizer(\n","        f\"Question: {question} Answer: {answer}\",\n","        truncation=True,\n","        max_length=512,\n","        padding=\"max_length\"\n","    )\n","\n","# Tokenizing the dataset\n","tokenized_dataset = dataset.map(tokenize_data, batched=True, remove_columns=[\"question\", \"answer\"])\n","\n","# Data collator to convert batch to tensors\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","\n","# Initializing Accelerator for memory-efficient training\n","accelerator = Accelerator()\n","\n","# Initializing optimizer\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","# Preparing model, optimizer, and data loaders with Accelerator\n","model, optimizer, tokenized_dataset = accelerator.prepare(model, optimizer, tokenized_dataset)\n","\n","# Training loop\n","for epoch in range(5):\n","    model.train()\n","    for batch in tokenized_dataset:\n","        batch = data_collator([batch])\n","\n","        # Moving batch to the correct device using accelerator\n","        batch = {k: v.to(accelerator.device) for k, v in batch.items()}\n","\n","\n","        print(f\"Input IDs shape: {batch['input_ids'].shape}\")\n","        print(f\"Input IDs: {batch['input_ids']}\")\n","        print(f\"Attention Mask shape: {batch['attention_mask'].shape}\")\n","        print(f\"Attention Mask: {batch['attention_mask']}\")\n","\n","        # Checking if the input has a sufficient sequence length\n","        if len(batch['input_ids'].shape) > 1 and batch['input_ids'].shape[1] > 1:\n","            # Pass the inputs to the model\n","            outputs = model(**batch)\n","            loss = outputs.loss\n","            accelerator.backward(loss)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        else:\n","            print(f\"Skipping batch with shape: {batch['input_ids'].shape}\")\n","\n","    print(f\"Epoch {epoch + 1} completed.\")\n","\n","# Saving the fine-tuned model\n","accelerator.wait_for_everyone()\n","model.save_pretrained(\"finetuned_llama_model\")\n","tokenizer.save_pretrained(\"finetuned_llama_model\")\n","print(\"Fine-tuned LLaMA model saved.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a0c440444dd54c05bc8f108a24be51c6","e555ce4e2452472e8eb29ba5b3093b5f","9df4652a857c46d0a41f5fd86e3b9675","a97cd7e98e80441e801ae2f1d21c2ebe","34aa05e758774eb28c64ff9a77e081d9","088a6a37c4074a2388205475dde5b3e9","853ebb896f184cc4957098ecd4a164ec","e117d96aee444249a4bd7e58921981e5","9e6dd690293644779fcd41954ffeae4c","8fe5a3732ef54d558c951aaff804590e","e93bae96facb43dfb0a09f59d988910d","2f69eba80913409d9f6dfc2bd0b3715a","45d46558ccde443cada1c8ed5ef6c1fb","d968dc73ee1a41ddb331e792de437fe4","b04256d204cf4eebbcfab04238427bac","406e856e67254867824c1fae2682a009","07586706bf0b49088052299f2d19effa","63e30aa7b7c24473bb8cf4e5689400ec","c93e258b4ea942de91c0fe6f31e9916e","60957a3fb2a94c8c97b80ad991da1c3d","52e4be24c7ce4bdca54073efdc438ced","777ec2a084864b1bba2d66e51b8c4a30"]},"id":"XaVcWqlaBiUt","executionInfo":{"status":"ok","timestamp":1727904001886,"user_tz":-330,"elapsed":291018,"user":{"displayName":"Udit Kosuru","userId":"07698625486027486284"}},"outputId":"a99adda6-5251-4623-dc08-55deb8f1b43e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0c440444dd54c05bc8f108a24be51c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/288 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f69eba80913409d9f6dfc2bd0b3715a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([619], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([11614], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([399], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([8610], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([338], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([6232], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([7694], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([1592], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([537], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([399], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([8610], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([21608], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([14861], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([619], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([11614], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([14861], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([338], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([6232], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([7694], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([1592], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([537], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([14861], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([21608], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([323], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([17061], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([619], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([11614], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([323], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([17061], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([338], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([6232], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([7694], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([1592], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([537], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([323], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([17061], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([21608], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([28962], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29968], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([619], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([11614], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([28962], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29968], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([338], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([6232], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([7694], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([1592], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([537], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([28962], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29968], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([21608], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([405], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29911], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3970], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29979], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29946], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([619], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([11614], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([405], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29911], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3970], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29979], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29946], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([338], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([6232], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([7694], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([1592], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([537], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([405], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29911], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3970], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29979], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29946], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([21608], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Epoch 4 completed.\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([1], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([894], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([6024], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([21608], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([399], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([8610], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([619], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([11614], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([399], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([8610], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([338], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([6232], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([7694], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([1592], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([537], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([399], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([8610], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([21608], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([14861], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([619], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([11614], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([14861], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([338], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([6232], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([7694], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([1592], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([537], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([14861], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([21608], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([323], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([17061], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([619], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([11614], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([323], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([17061], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([338], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([6232], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([7694], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([1592], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([537], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([323], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([17061], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([21608], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([28962], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29968], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([619], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([11614], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([28962], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29968], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([338], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([6232], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([7694], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([1592], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([537], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([28962], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29968], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([21608], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([405], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29911], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3970], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29979], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29946], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([619], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([11614], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([405], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29911], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3970], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29979], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29946], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([338], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([6232], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([7694], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([1592], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([537], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([310], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([405], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29911], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3970], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29979], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([297], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29906], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29946], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29899], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29941], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29896], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29871], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29901], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29900], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([29973], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([742], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([525], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([5618], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([526], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([278], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([3001], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Input IDs shape: torch.Size([1])\n","Input IDs: tensor([21608], device='cuda:0')\n","Attention Mask shape: torch.Size([1])\n","Attention Mask: tensor([1], device='cuda:0')\n","Skipping batch with shape: torch.Size([1])\n","Epoch 5 completed.\n","Fine-tuned LLaMA model saved.\n"]}]},{"cell_type":"code","source":["# Checking the contents of financial_data to see which keys are present\n","print(financial_data[:5])\n","\n","# Preparing financial documents for FAISS, handling missing fields\n","documents = []\n","for company in financial_data:\n","    # Handling missing fields gracefully with defaults\n","    ticker = company.get('ticker', 'Unknown')\n","    total_assets = company.get('Total Assets', 'N/A')\n","    total_liabilities = company.get('Total Liabilities', 'N/A')\n","    shareholder_equity = company.get('Total Stockholder Equity', 'N/A')\n","\n","    document = f\"{ticker} Financials: Total Assets {total_assets}, Total Liabilities {total_liabilities}, Shareholder Equity {shareholder_equity}\"\n","    documents.append(document)\n","\n","index, embedding_model, embedding_tokenizer = setup_faiss(documents)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281,"referenced_widgets":["b1d1d2214269417f8f552ff331e3c2d1","9c5c619d280646e18bd938c5f655e949","18b2da20fee847a59c8df89d6c7c3dbf","752b36acc5724438bfa821dfa1db2518","4453335771524a8ba9503445423b16e4","f84af7c135474ded8fec280bc9959fb1","b94bbfe741304160a44d72f040e82201","cbfbf859c02a466c89723c8f82f6e8cb","92c09ecc585b4911bc1e8ade267e06bb","3cb22b1c24874ce29bf051796da1aea1","101923033bcd416bba840be779df9697","75a25e80847c4d389509642655b29b77","2c678d6f9d9642ea9d1461704ca6d884","aad37e9ce16b49d198d1f1726f1970f1","a1beabf33b2e472cb918273ab8c4f29a","efd1288716e3406587dceab53a8be604","439e8f7df38e4c21910f49c5a97a5ed1","f69bb25d848f4301912da43767acfedb","213e758a895b44c081307211c09a89f1","0b2ede2dacae4fb6bb8288bc19aeb0c3","044676487ff44eb2a26283a1d1cf5507","96f3054a34874a4f92052ba858513de3","38177054c4724036b378964c4a115c56","75aa067577044ac0929c3fbe9eaecb32","5363636a20b34bef8adec9c158f66cba","7f5fbc36034047f28636a3f553ba31ed","b2b1e7a8b26942f8bbca519b1e6f8cff","87afc91a30bb4cb7885660f8f218db23","87c3ec6b40274528b5ac6f09ea313386","5a21454e851e4577a09e381a0a965efc","61ac09c8ad654912b640ccfb36a636ed","75fe3725a2dc45098029aaff5dd0bb72","41cc20a7055b45839df5900ad2aeb677","d42b23cf5835420ea1817605f08b51dd","3d59c2b4cb2e44d893ed902b96bc0fbc","a35d7c87f5814ec0b2271d735a91498a","d8444feee8d54f608ea3b156e6e8496f","6f6089fc7964445ca7728f81013406f1","074b8227e8c34efc8d057a1a87b0a235","142e7cefb168423387cb311b3d1730ca","7a5a301202b24274a2fdf08f6bb6c3e4","cc4aab3fa54b4558bf344c6155f73033","b0870ecdc3454ee19e1b49b449f2e34f","1721e4aaa3c84eb4ba0366d7f6107b65","015b3d49e00c4aea8758ba22921a3872","6b050aed961044b7bc5601cd3e8582f7","67092193bb4d46de95495230b2274574","0ae687fee4e2476ab1a1b4dc7dd212b1","2095a66dc0aa439e9ddde8c4c4ec2967","be80fffeba734553a786a3928ab737bd","b6380662e5934df087283d5e9621b475","8c356e5d61304afb9650c3150d448103","cacd9387fb9f4fd6af55d1b9883793e3","7a13540f4ebf4cbabd08c21b719289af","4a38da4775924d7bab5b50934cd99dac","97e699da53f24284872ee144d6a7c559","45f5a728791b4c6eaccc086df8577afa","da559cb2d86c40c0af25983b2aad2824","323200ae36c449cfa2e56f5de49ede8c","797538783986442986b108876206e641","d45a47989fb343b0b68d613bed765376","4aa5e08c240f4ffbaa93f8e958b37332","365a7bc031774bc4a359073d0e4acbe4","d93b5ba1bad64fc5b4e82a77c410d54b","0f30dd1abd0c4a3687f45f29cce98028","5f7cf3df17e04d34875ecd88acbae3b5"]},"id":"ljVoHF3cBrRT","executionInfo":{"status":"ok","timestamp":1727904389982,"user_tz":-330,"elapsed":10706,"user":{"displayName":"Udit Kosuru","userId":"07698625486027486284"}},"outputId":"9723333d-1edb-4905-e5c7-cf6317f936cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'question': 'What are the total assets of WFC in 2023-12-31 00:00:00?', 'answer': 'The total assets of WFC in 2023-12-31 00:00:00 were 1932468000000.0 USD.'}, {'question': 'What are the total liabilities of WFC in 2023-12-31 00:00:00?', 'answer': 'The total liabilities of WFC in 2023-12-31 00:00:00 were 207569000000.0 USD.'}, {'question': 'What is the total shareholder equity of WFC in 2023-12-31 00:00:00?', 'answer': 'The total shareholder equity of WFC in 2023-12-31 00:00:00 was None USD.'}, {'question': 'What are the total assets of MA in 2023-12-31 00:00:00?', 'answer': 'The total assets of MA in 2023-12-31 00:00:00 were 42448000000.0 USD.'}, {'question': 'What are the total liabilities of MA in 2023-12-31 00:00:00?', 'answer': 'The total liabilities of MA in 2023-12-31 00:00:00 were 14344000000.0 USD.'}]\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1d1d2214269417f8f552ff331e3c2d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75a25e80847c4d389509642655b29b77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38177054c4724036b378964c4a115c56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d42b23cf5835420ea1817605f08b51dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"015b3d49e00c4aea8758ba22921a3872"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97e699da53f24284872ee144d6a7c559"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Preparing financial documents for FAISS based on questions and answers\n","documents = [f\"Question: {entry['question']} Answer: {entry['answer']}\" for entry in financial_data]\n","\n","\n","index, embedding_model, embedding_tokenizer = setup_faiss(documents)\n","\n","print(f\"Total documents indexed: {len(documents)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q11DJe8FIbKa","executionInfo":{"status":"ok","timestamp":1727904475325,"user_tz":-330,"elapsed":8501,"user":{"displayName":"Udit Kosuru","userId":"07698625486027486284"}},"outputId":"a3fe0e3b-8317-43ed-f398-ef1908a20399"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total documents indexed: 288\n"]}]},{"cell_type":"code","source":["import torch\n","import faiss\n","from transformers import AutoModel, AutoTokenizer\n","\n","#  Querying FAISS index for relevant financial documents based on user query\n","def query_faiss(query, index, embedding_model, embedding_tokenizer, documents, k=3):\n","    # Tokenize and encode the query\n","    encoded_query = embedding_tokenizer([query], return_tensors=\"pt\", padding=True, truncation=True)\n","\n","    # Moving inputs to the same device as the model\n","    encoded_query = {k: v.to(embedding_model.device) for k, v in encoded_query.items()}\n","\n","    # Generating the embedding for the query\n","    with torch.no_grad():\n","        query_embedding = embedding_model(**encoded_query).last_hidden_state.mean(dim=1).cpu().numpy()\n","\n","    # Searching FAISS index to get top-k results\n","    _, indices = index.search(query_embedding, k)\n","\n","    # Retrieving the top-k relevant documents\n","    relevant_docs = [documents[i] for i in indices[0]]\n","\n","    return relevant_docs\n","\n","# Example query\n","user_query = \"What are the total assets of AAPL?\"\n","\n","# Query FAISS to retrieve relevant financial documents\n","relevant_docs = query_faiss(user_query, index, embedding_model, embedding_tokenizer, documents)\n","\n","# Display the results\n","print(\"Relevant Financial Information:\")\n","for i, doc in enumerate(relevant_docs, 1):\n","    print(f\"Result {i}: {doc}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4HVQYHLItdV","executionInfo":{"status":"ok","timestamp":1727904541629,"user_tz":-330,"elapsed":767,"user":{"displayName":"Udit Kosuru","userId":"07698625486027486284"}},"outputId":"2b90c67d-76f2-4cd9-9e36-80a2d6ed635f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Relevant Financial Information:\n","Result 1: Question: What are the total assets of AAPL in 2023-09-30 00:00:00? Answer: The total assets of AAPL in 2023-09-30 00:00:00 were 352583000000.0 USD.\n","Result 2: Question: What is the total shareholder equity of AAPL in 2023-09-30 00:00:00? Answer: The total shareholder equity of AAPL in 2023-09-30 00:00:00 was None USD.\n","Result 3: Question: What are the total liabilities of AAPL in 2023-09-30 00:00:00? Answer: The total liabilities of AAPL in 2023-09-30 00:00:00 were 95281000000.0 USD.\n"]}]},{"cell_type":"code","source":["#  Adding Neo4j Integration\n","from py2neo import Graph, Node, Relationship\n","\n","graph = Graph(\"neo4j+s://8d1ce1f5.databases.neo4j.io\", auth=(\"neo4j\", \"1kb73GatQB5RE_hfad_pOVdM-F8v3RDbE9PHCYBmGiI\"))\n","\n","def query_neo4j(company_ticker):\n","    query = f\"\"\"\n","    MATCH (c:Company)-[:HAS_FINANCIAL_DATA]->(f:Financials)\n","    WHERE c.name='{company_ticker}'\n","    RETURN f.total_assets, f.total_liabilities, f.shareholder_equity\n","    \"\"\"\n","    result = graph.run(query).data()\n","\n","    if result:\n","        financials = result[0]\n","        return f\"Total Assets: {financials['f.total_assets']}, Total Liabilities: {financials['f.total_liabilities']}, Shareholder Equity: {financials['f.shareholder_equity']}\"\n","    else:\n","        return \"No structured financial data found for this company in Neo4j.\"\n"],"metadata":{"id":"IRc3QIsAJ9A3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Full Pipeline\n","def generate_llm_response(query, retrieved_docs, llama_model, llama_tokenizer):\n","    # Combine the user query with retrieved FAISS documents\n","    context = \"\\n\".join(retrieved_docs)\n","    full_prompt = f\"User question: {query}\\n\\nFinancial Information:\\n{context}\\n\\nAnswer:\"\n","\n","    # Tokenize the input and move it to the GPU\n","    inputs = llama_tokenizer(full_prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","    # Generate a response using the LLaMA model, controlling max_new_tokens\n","    with torch.no_grad():\n","        output = llama_model.generate(**inputs, max_new_tokens=150)\n","\n","    # Decode the generated response\n","    response = llama_tokenizer.decode(output[0], skip_special_tokens=True)\n","    return response\n","\n","\n","def full_pipeline(user_query, faiss_index, embedding_model, embedding_tokenizer, documents, llama_model, llama_tokenizer):\n","    company_ticker = user_query.split()[-1].upper().replace(\"?\", \"\")\n","\n","    neo4j_data = query_neo4j(company_ticker)\n","\n","    if \"No structured financial data\" not in neo4j_data:\n","        return f\"Neo4j Financial Data: {neo4j_data}\"\n","    else:\n","        relevant_docs = query_faiss(user_query, faiss_index, embedding_model, embedding_tokenizer, documents)\n","        final_response = generate_llm_response(user_query, relevant_docs, llama_model, llama_tokenizer)\n","        return f\"FAISS-based Financial Data: {final_response}\"\n"],"metadata":{"id":"6B0qWRevKZ2U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_query = \"Should I invest in AAPL?\"\n","\n","# Run the full pipeline\n","final_response = full_pipeline(user_query, index, embedding_model, embedding_tokenizer, documents, model, tokenizer)\n","\n","# Display the final response\n","print(\"Final Response:\")\n","print(final_response)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95KZBMYeKgqi","executionInfo":{"status":"ok","timestamp":1727905174112,"user_tz":-330,"elapsed":15035,"user":{"displayName":"Udit Kosuru","userId":"07698625486027486284"}},"outputId":"15dbb1bf-d958-4663-8391-7ad59f1cedb1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Response:\n","FAISS-based Financial Data: User question: Should I invest in AAPL?\n","\n","Financial Information:\n","Question: What is the total shareholder equity of AAPL in 2023-09-30 00:00:00? Answer: The total shareholder equity of AAPL in 2023-09-30 00:00:00 was None USD.\n","Question: What are the total assets of AAPL in 2023-09-30 00:00:00? Answer: The total assets of AAPL in 2023-09-30 00:00:00 were 352583000000.0 USD.\n","Question: What are the total liabilities of AAPL in 2023-09-30 00:00:00? Answer: The total liabilities of AAPL in 2023-09-30 00:00:00 were 95281000000.0 USD.\n","\n","Answer:\n","The total shareholder equity of AAPL in 2023-09-30 00:00:00 was None USD.\n","\n","The total assets of AAPL in 2023-09-30 00:00:00 were 352583000000.0 USD.\n","\n","The total liabilities of AAPL in 2023-09-30 00:00:00 were 95281000000.0 USD.\n","\n","The shareholder equity of AAPL in 20\n"]}]},{"cell_type":"code","source":["import yfinance as yf\n","\n","def get_ground_truth(ticker):\n","    stock = yf.Ticker(ticker)\n","    balance_sheet = stock.balance_sheet\n","    if not balance_sheet.empty:\n","        total_assets = balance_sheet.loc[\"Total Assets\"].iloc[0] if \"Total Assets\" in balance_sheet.index else None\n","        total_liabilities = balance_sheet.loc[\"Total Liabilities\"].iloc[0] if \"Total Liabilities\" in balance_sheet.index else None\n","        total_equity = balance_sheet.loc[\"Total Stockholder Equity\"].iloc[0] if \"Total Stockholder Equity\" in balance_sheet.index else None\n","\n","        return {\n","            \"Total Assets\": total_assets,\n","            \"Total Liabilities\": total_liabilities,\n","            \"Total Stockholder Equity\": total_equity\n","        }\n","    return None\n","\n","# Example to generate ground truth for AAPL\n","ground_truth = get_ground_truth(\"AAPL\")\n","print(ground_truth)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ru9RHk4UMOic","executionInfo":{"status":"ok","timestamp":1727905463025,"user_tz":-330,"elapsed":489,"user":{"displayName":"Udit Kosuru","userId":"07698625486027486284"}},"outputId":"5a70ebf5-4577-4851-c69d-1883f894377a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Total Assets': 352583000000.0, 'Total Liabilities': None, 'Total Stockholder Equity': None}\n"]}]},{"cell_type":"code","source":["from nltk.translate.bleu_score import sentence_bleu\n","\n","# Example LLaMA-generated response\n","generated_response = \"The total assets of AAPL in 2021 were 350 billion USD.\"\n","\n","# Ground truth retrieved from Yahoo Finance\n","ground_truth = get_ground_truth(\"AAPL\")\n","ground_truth_answer = f\"The total assets of AAPL in 2021 were {ground_truth['Total Assets']} USD.\"\n","\n","#  BLEU score\n","reference = [ground_truth_answer.split()]  # Ground truth answer\n","candidate = generated_response.split()  # Generated response from LLaMA\n","\n","bleu_score = sentence_bleu(reference, candidate)\n","print(f\"BLEU score: {bleu_score}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWchRPjSMW6W","executionInfo":{"status":"ok","timestamp":1727905497390,"user_tz":-330,"elapsed":1065,"user":{"displayName":"Udit Kosuru","userId":"07698625486027486284"}},"outputId":"0c48f1d8-fa27-4bd0-f825-1ebc38805f8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU score: 0.6989307622784944\n"]}]}]}